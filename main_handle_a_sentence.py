import argparse
import emoji
from pinyin_model.after_9w_utils import after_9w_filter
from fixed_model.fixed_data_process import process_fixed_iter
from preprocess.load_fixed_data import load_2_fixed_data
from preprocess.load_pickle_data import load_pickle_data_from_file
from preprocess.load_data import load_data_for_bert_verb
from standard_translator.handle_one_sentence import general_process
from bert_model.bert_utils import bert_fill_mask, creat_fill_mask, bert_handle_ride, bert_handle_verb, bert_handle_adj
from bert_model.bert_verb_process_epoch import process_bert_iter
from bert_model.bert import initialize_bert


def translate_a_sentence(opt):
    """
    å‘½ä»¤è¡Œapiï¼Œç¿»è¯‘å•æ¡å¥å­
    :param opt: å‚è§æœ¬æ–‡ä»¶ä¸‹æ–¹å‚æ•°æç¤ºæˆ–ä½¿ç”¨-h
    :return: ç¿»è¯‘å¥½çš„å¥å­
    """
    sentence = opt.sentence
    init_sentence = opt.sentence
    if len(emoji.emoji_list(sentence)) == 0:
        print('no emoji found in sentence')
        return sentence

    if opt.context == 'normal':
        result = after_9w_filter(sentence)
        if result:
            return result

    if opt.fixed:
        emoji_fixed_dict, redup_AA_list = load_2_fixed_data()
        inner_filter = load_pickle_data_from_file('./dataset/inner_filter.data')
        result = process_fixed_iter(redup_AA_list, emoji_fixed_dict, sentence, 0.66, 1, 0, 0, inner_filter)
        if result:
            return result

    general_result = general_process(sentence)

    if opt.bert:
        fill_mask = creat_fill_mask()
        model, tokenizer = initialize_bert()
        id2bertverbs, verbs_list = load_data_for_bert_verb()
        # bertå›ºå®šæ­é…å•MASKå¡«ç©º
        result = bert_fill_mask(sentence, fill_mask)
        if result:
            return result
        # bertæ·»åŠ ä¸€èˆ¬åŠ¨è¯æ£€æµ‹
        result = process_bert_iter(fill_mask, verbs_list, init_sentence, sentence)
        if result:
            return result
        # bertæ·»åŠ ä¸€èˆ¬åŠ¨è¯æ£€æµ‹v2
        result = bert_handle_verb(init_sentence, sentence, model, tokenizer)
        if result:
            return result
        # bertäº¤é€šå·¥å…·ç±»åŠ¨è¯æ£€æµ‹
        result = bert_handle_ride(init_sentence, sentence, model, tokenizer)
        if result:
            return result
        # bertå½¢å®¹è¯æ£€æµ‹
        result = bert_handle_adj(init_sentence, sentence, model, tokenizer, [], mode='on-line')
        if result:
            return result

    return general_result


def translate_a_sentence_inner(sample_emoji, context, fixed, bert):
    """
    ç¿»è¯‘å•æ¡å¸¦æœ‰emojiçš„å¥å­
    :param sample_emoji: å¸¦æœ‰emojiçš„å¥å­
    :param context: å½“å‰è¯­å¢ƒï¼Œé€‚ç”¨äºæŠ–éŸ³é»‘ç°äº§è¯­å¢ƒå’Œä¸€èˆ¬è¯­å¢ƒ[douyin|normal]
    :param fixed: æ˜¯å¦ä½¿ç”¨å›ºå®šæ­é…æ¨¡å‹ï¼Œé»˜è®¤ä¸ºä½¿ç”¨
    :param bert: æ˜¯å¦ä½¿ç”¨bertæ¨¡å‹ï¼Œé»˜è®¤ä¸ºä½¿ç”¨ï¼ˆå¤„ç†è¾ƒæ…¢ï¼‰
    :return: ç¿»è¯‘å¥½çš„å¥å­
    """
    sentence = sample_emoji
    init_sentence = sample_emoji
    if len(emoji.emoji_list(sentence)) == 0:
        print('no emoji found in sentence')
        return sentence

    if context == 'normal':
        result = after_9w_filter(sentence)
        if result:
            return result

    if fixed:
        emoji_fixed_dict, redup_AA_list = load_2_fixed_data(log=False)
        inner_filter = load_pickle_data_from_file('./dataset/inner_filter.data')
        result = process_fixed_iter(redup_AA_list, emoji_fixed_dict, sentence, 0.66, 1, 0, 0, inner_filter)
        if result:
            return result

    general_result = general_process(sentence, log=False)

    if bert:
        fill_mask = creat_fill_mask(log=False)
        model, tokenizer = initialize_bert()
        id2bertverbs, verbs_list = load_data_for_bert_verb(log=False)
        # bertå›ºå®šæ­é…å•MASKå¡«ç©º
        result = bert_fill_mask(sentence, fill_mask)
        if result:
            return result
        # bertæ·»åŠ ä¸€èˆ¬åŠ¨è¯æ£€æµ‹
        result = process_bert_iter(fill_mask, verbs_list, init_sentence, general_result)
        if result:
            return result
        # bertæ·»åŠ ä¸€èˆ¬åŠ¨è¯æ£€æµ‹v2
        result = bert_handle_verb(init_sentence, general_result, model, tokenizer)
        if result:
            return result
        # bertäº¤é€šå·¥å…·ç±»åŠ¨è¯æ£€æµ‹
        result = bert_handle_ride(init_sentence, general_result, model, tokenizer)
        if result:
            return result
        # bertå½¢å®¹è¯æ£€æµ‹
        result = bert_handle_adj(init_sentence, general_result, model, tokenizer, [], mode='on-line')
        if result:
            return result

    return general_result


if __name__ == '__main__':
    """
    *Tips*
    æœ¬ç¨‹åºèƒ½å¤Ÿå¤„ç†ä¸€èˆ¬çš„å«emojiæ–‡æœ¬ç¿»è¯‘é—®é¢˜ï¼Œå…¶ä¸­ä½¿ç”¨åˆ°çš„ä¸»è¦æŠ€æœ¯åŒ…æ‹¬ngramæ¨¡å‹ã€å›ºå®šæ­é…æ¨¡å‹å’Œbertè¯­è¨€æ¨¡å‹ç­‰ã€‚
    æœ¬ç¨‹åºæ˜¯å¯¹ç«èµ›ä¸­ä½¿ç”¨çš„æ¨¡å‹åšäº†æ³›ç”¨æ€§å‡çº§ä¹‹åçš„ç¨‹åºï¼Œè‹¥ç›´æ¥å°†æœ¬ç¨‹åºç”¨åœ¨ç«èµ›æµ‹è¯•é›†ä¸Šå°†ä¼šå¾—åˆ°84åˆ†å·¦å³çš„ç»“æœï¼ˆå·®äº†æ‹¼éŸ³æ£€æµ‹æ¨¡å—å’Œè¯­å¢ƒé’ˆå¯¹æ€§å¤„ç†ï¼Œ
    è¯¦æƒ…å‚è§Readmeï¼‰ï¼Œè‹¥æ‚¨æƒ³å¯¹ç«èµ›æµ‹è¯•é›†è¿›è¡ŒéªŒè¯ï¼Œè¯·è¿è¡Œmain_test_dataset.py
    """
    # pythonç¨‹åºæ¨¡å¼
    print(translate_a_sentence_inner('äººç”Ÿè¦å¾€å‰çœ‹ã€ç”Ÿå‘½ä¸€ç‰‡å¥½å…‰æ™¯ã€ğŸ’ªä¸€åˆ‡éƒ½ä¼šè¶Šæ¥è¶Šå¥½çš„', 'douyin', 1, 1))
    print(translate_a_sentence_inner('é€€ä¼è¯å¯ä»¥å…è´¹åğŸšŒå’ŒğŸš‡æˆ‘ä¸€ç›´åœ¨ç”¨', 'douyin', 1, 1))
    print(translate_a_sentence_inner('ç¾å›½ä¾µç•¥ğŸ“æ‹‰å…‹ç‚¸ä¸­å›½å¤§ä½¿é¦†æ—¶ä½ å¹²å•¥å»äº†', 'douyin', 1, 1))

    # å‘½ä»¤è¡Œæ¨¡å¼
    # ï¼ˆå‘½ä»¤è¡Œå¯èƒ½ä¼šå‡ºç°emojiç¼–ç é—®é¢˜ã€‚è‹¥è¦ä½¿ç”¨è¯·æ‰“å¼€ä¸‹æ–¹æ³¨é‡Šï¼Œä½¿ç”¨æ–¹æ³•å‚è§python main_handle_a_sentence.py -hï¼‰
    # parser = argparse.ArgumentParser()
    # parser.add_argument('--sentence', required=True, type=str,
    #                     help='emoji sentences waiting for translating.')
    # parser.add_argument('--context', type=str, default='douyin',
    #                     help='select the emoji sentence\'s context.[douyin(defualt)|normal]')
    # parser.add_argument('--fixed', type=bool, default=True,
    #                     help='whether to use the fixed matching module.[True(default)|False]')
    # parser.add_argument('--bert', type=bool, default=True,
    #                     help='whether to use bert module to enhance the translation model.[True(default)|False]')
    #
    # opt = parser.parse_args()
    #
    # translate_a_sentence(opt)



